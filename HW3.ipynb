{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBYeA3E8sw7L"
      },
      "source": [
        "#14757 Homework 3 (150 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woTOf5zhYmMY"
      },
      "source": [
        "## **Due:** Wednesday October 23 at 3pm ET / 12 noon PT\n",
        "\n",
        "## Submission Instructions\n",
        "\n",
        "*   Download your completed notebook by clicking File->Download .ipynb and submit it on Gradescope\n",
        "*   Check your submission on Gradescope to make sure that all your code, code output and written responses appear correctly\n",
        "\n",
        "## Tips for getting started\n",
        "\n",
        "*   Make sure to set your Colab runtime type to GPU hardware acceleration.\n",
        "\n",
        "*   You will require knowledge of PyTorch to complete this assignment. We recommend that you read all four sections of the following tutorial. The starter code for Problem 2 is adapted from the last section.\n",
        "\n",
        "  https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html\n",
        "\n",
        "*   As you work on this assignment you will likely need to refer to the PyTorch documentation.\n",
        "\n",
        "  https://pytorch.org/docs/stable/index.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6ClORY3UaDV"
      },
      "source": [
        "## Problem 1: Gradescope Autograder Placeholder (0 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIgsAy69UkUm"
      },
      "source": [
        "Gradescope requires that problem 1 be autograded for code submissions, but there are no autograded problems. Continue to problem 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OasOGO3AZdjv"
      },
      "source": [
        "## Problem 2: Tweaking a Convolutional Neural Network (90 pts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "Bl8UR4tPUDL_",
        "outputId": "6f1b0df8-525d-434c-8f91-965772c91115"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "Adam.__init__() got an unexpected keyword argument 'momentum'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-4d0ab8bba12b>\u001b[0m in \u001b[0;36m<cell line: 158>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;31m# ADAGRAD: 34%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;31m# RMSprop: 51%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;31m# Train the network on the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Adam.__init__() got an unexpected keyword argument 'momentum'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# Num workers 2 doesn't work with CUDA on CoLab so multiprocessing used\n",
        "# import torch.multiprocessing as mp\n",
        "# mp.set_start_method('spawn', force=True)\n",
        "\n",
        "\n",
        "# Load and normalize the CIFAR10 training and test datasets\n",
        "## ORIGINAL = 55%\n",
        "\n",
        "\n",
        "# MOVING TO GPU IF AVAILABLE\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# torch.set_default_device(device)\n",
        "print(device)\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# INCREASE THE BATCH SIZE FOR TRAINING\n",
        "'''\n",
        "Batch Size seems to have had the largest effect on accuracy compared to all\n",
        "other methods implemented (3rd CONV layer, Dropout, Epochs)\n",
        "SGD ONLY\n",
        "4: 55%\n",
        "8: 53%\n",
        "16: 49%\n",
        "20: 48%\n",
        "32: 45%\n",
        "\n",
        "ADAM and 64 feature maps with 3x3 kernel with padding\n",
        "5 Epochs:\n",
        "20: 64%\n",
        "50: 65%\n",
        "100: 65%\n",
        "\n",
        "10 Epochs:\n",
        "50: 68%\n",
        "100: 67%\n",
        "'''\n",
        "# batch_size = 4 ## ORIGINAL\n",
        "batch_size = 50 # better divisibility between batchsizes and 10k set if % 10\n",
        "\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Define a Convolutional Neural Network\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    '''\n",
        "    Using 2D Convolution operation to create kernels:\n",
        "    Formula: Output Size = ((Input Size - Kernel Size + 2 * Padding)/Stride) + 1\n",
        "     Conv Layer Observations\n",
        "      Testing:  Applying a smaller kernel value of 3x3 with stride 1 and padding 1\n",
        "                vastly outperformed the kernel sizes of 5x5 with less feature maps.\n",
        "      Assumption: Smaller kernel allowed model to retain finer details while the\n",
        "                  padding and stride allowed it to retain spatial details.\n",
        "     Linear Layer Observations\n",
        "\n",
        "    nn.Conv2d(x1,x2,x3)\n",
        "      x1 = num input channels. 1st layer is usually 3 for RGB or 1 for grayscale\n",
        "      x2 = num output channles. num kernels that layer will learn resulting in the\n",
        "           same num of feature maps, 1 for each filter.\n",
        "      x3 = size of kernels. single int mens x3 x x3 like 5x5 or 3x3, or tuple\n",
        "           with height and width\n",
        "\n",
        "      - The next layer's input = the previous layer's output channel/feature maps\n",
        "      - Layer 3 reduces the kernel size to capture more details\n",
        "      - Little to no difference in 3rd Conv layer output from 32 to 64 with first\n",
        "            going from 3, 6 so tried upping the feature map and lowering the kernel size\n",
        "    ReLU:\n",
        "      Introduces non-linearity so that model can capture complex features from\n",
        "      nonlinear patters. Needed after every linear layer performs matmul and adding\n",
        "      bias. ReLU takes only the positive values after that and zeros where other\n",
        "      things would have been negative with max(0,x) activation function. This\n",
        "      basically introduces sparsity which reduces overfitting and improves efficiency.\n",
        "      However there are limits\n",
        "        Observation: 3rd ReLU actually brought accuracy down 1% meaning there's a limit\n",
        "                    to the benefits. This even happened after evening out the reduction\n",
        "                    between in linear transformations.\n",
        "        Assumption: 3rd ReLU could be overfitting or the limits of the linear transform\n",
        "                    were reached quickly after the 3rd Conv layer\n",
        "    Pooling:\n",
        "      Form of dimensionality reduction that reduces the spatial dimensions of\n",
        "      the feature maps (width, height). Helps prevent overfitting and detection\n",
        "      of features more robust by highlighting the most prominent features in maps\n",
        "\n",
        "      This net reduces width and height by half using a 2x2 kernel with a stride of 2\n",
        "      So 28x28 gets reduced to 14x14 and so on.\n",
        "    Dropout:\n",
        "      Simple technique to randomly drop a % of neurons so that they're ignored\n",
        "      on a forward pass and weight updates are not applied on backprop.\n",
        "\n",
        "      Forces network to learn more robust features on each pass and averages those\n",
        "      to effectively make an averaged model of neurons.\n",
        "\n",
        "    '''\n",
        "    self.dropout = nn.Dropout(p=0.3) # APPLY DROPOUT TO INPUT LAYER\n",
        "    self.conv1 = nn.Conv2d(3, 16, 3, stride=1, padding=1)\n",
        "    self.conv2 = nn.Conv2d(16, 32, 3, stride=1, padding=1)\n",
        "    self.conv3 = nn.Conv2d(32, 64, 3, stride=1, padding=1)  # ADDING NEW CONV LAYER\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.fc1 = nn.Linear(64 * 4 * 4, 256)\n",
        "    self.fc2 = nn.Linear(256, 64)\n",
        "    self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    '''\n",
        "    Big source of errors: make sure that the last layer does not pool\n",
        "    In this case, conv3 otherwise, very hard to make this size of 32 feature map\n",
        "    map correctly to the flattened feature map from conv3 given the 2x2 kernel\n",
        "    and 2 stride coming down from a 3x3 kernel\n",
        "    '''\n",
        "    x = self.dropout(x)  # APPLY DROPOUT TO INPUT LAYER\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = self.pool(F.relu(self.conv3(x))) # FORWARD PASS FOR NEW CONV LAYER,\n",
        "    # x = x.view(-1, 64 * 4 * 4)\n",
        "    x = torch.flatten(x, 1) # same effect, but much better coding because done dynamically\n",
        "    x = F.relu(self.fc1(x))\n",
        "    # x = F.relu(self.fc2(x))\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        "# MOVING TO GPU IF AVAILABLE\n",
        "net = Net().to(device)\n",
        "\n",
        "# Define a loss function\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# CHANGE OPTIMIZATION ALGORITHM: from SGD to ADAM to ADAGRAD\n",
        "'''\n",
        "SGD:     48%\n",
        "ADAM:    54% | Makes sense since it combines SGD-Momentum and RMSprop\n",
        "         64% | Using smaller kernel, padding, and more features with 2x RELU\n",
        "ADAGRAD: 34%\n",
        "RMSprop: 51%\n",
        "'''\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "# Train the network on the training data\n",
        "\n",
        "print('Starting Training')\n",
        "\n",
        "# INCREASE NUMBER OF EPOCHS\n",
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(trainloader, 0):\n",
        "    # get the inputs; data is a list of [inputs, labels]\n",
        "    inputs, labels = data\n",
        "    inputs, labels = inputs.to(device), labels.to(device) # MOVING TO GPU IF AVAILABLE\n",
        "\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward + backward + optimize\n",
        "    outputs = net(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "    if i % 200 == 199:    # print every 2000 mini-batches\n",
        "      print('[%d, %5d] loss: %.3f' %\n",
        "            (epoch + 1, i + 1, running_loss / 2000))\n",
        "      running_loss = 0.0\n",
        "\n",
        "print('Finished Training', end='\\n\\n')\n",
        "\n",
        "# Test the network on the test data\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for data in testloader:\n",
        "    images, labels = data\n",
        "    images, labels = images.to(device), labels.to(device)  # MOVING TO GPU IF AVAILABLE\n",
        "    outputs = net(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfVPzCdoVoZY"
      },
      "source": [
        "In this problem you will tweak an existing convolutional neural network image classifier that runs on the CIFAR-10 data set.\n",
        "\n",
        "The starter code is adapted from the tutorial at https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html.\n",
        "\n",
        "First run the cell below to observe the following steps.\n",
        "\n",
        "* Load and normalize the CIFAR-10 training and test datasets using ``torchvision``\n",
        "* Define a Convolutional Neural Network\n",
        "* Define a loss function\n",
        "* Train the network on the training data\n",
        "* Test the network on the test data\n",
        "\n",
        "Now tweak the code in the cell below as follows.\n",
        "\n",
        "* (20 pts) Train the model on a GPU\n",
        "* (20 pts) Add one more convolutional layer to the model\n",
        "* (20 pts) Apply dropout to the input layer\n",
        "* (10 pts) Increase the batch size for training\n",
        "* (10 pts) Increase the number of training epochs\n",
        "* (10 pts) Change the optimization algorithm for training\n",
        "\n",
        "We will not grade you on the accuracy of your classifier, just on the tweaks themselves."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AK_r14fqjMY6"
      },
      "source": [
        "## Problem 3: Attacking a Neural Network Classifier (60 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxq6diKiCFpF"
      },
      "source": [
        "In this problem you will implement two evasion attacks against a neural network classifier for the MNIST handwritten digits data set.\n",
        "\n",
        "The starter code is adapted from the following tutorial that you may find useful to read:\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/fgsm_tutorial.html\n",
        "\n",
        "Run the cell below to\n",
        "\n",
        "*   load the MNIST handwritten digit test set\n",
        "*   define the neural network structure and load pretrained parameters\n",
        "*   define test and display helper functions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TW-quUN9LWID"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# MNIST Test dataset and dataloader declaration\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "  datasets.MNIST('../data', train=False, download=True,\n",
        "                 transform=transforms.Compose([transforms.ToTensor(),])),\n",
        "                 batch_size=1, shuffle=True)\n",
        "\n",
        "# LeNet Model definition\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "    self.conv2_drop = nn.Dropout2d()\n",
        "    self.fc1 = nn.Linear(320, 50)\n",
        "    self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "    x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "    x = x.view(-1, 320)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.dropout(x, training=self.training)\n",
        "    x = self.fc2(x)\n",
        "    return F.log_softmax(x, dim=1)\n",
        "\n",
        "# Define what device we are using\n",
        "print(\"CUDA Available: \",torch.cuda.is_available())\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize the network\n",
        "model = Net().to(device)\n",
        "\n",
        "# Load the pretrained model\n",
        "!mkdir ./data/\n",
        "!wget http://www.andrew.cmu.edu/user/dvaroday/14757/data/hw3/lenet_mnist_model.pth\n",
        "!mv lenet_mnist_model.pth ./data\n",
        "pretrained_model = \"data/lenet_mnist_model.pth\"\n",
        "model.load_state_dict(torch.load(pretrained_model, map_location='cpu'))\n",
        "\n",
        "# Set the model in evaluation mode. In this case this is for the dropout layers.\n",
        "model.eval()\n",
        "\n",
        "# HELPER FUNCTIONS\n",
        "\n",
        "# Test attack_fn() on test data\n",
        "def test(attack_fn, model, device, test_loader, epsilon):\n",
        "  # Accuracy counter\n",
        "  correct = 0\n",
        "  adv_examples = []\n",
        "\n",
        "  # Loop over all examples in test set\n",
        "  for data, target in test_loader:\n",
        "\n",
        "    # Send the data and label to the device\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    # Set requires_grad attribute of tensor. Important for Attack\n",
        "    data.requires_grad = True\n",
        "    # Call attack function\n",
        "    perturbed_data = attack_fn(data, target, epsilon)\n",
        "    # Re-classify the perturbed image\n",
        "    output = model(perturbed_data)\n",
        "\n",
        "    # Check for success\n",
        "\n",
        "    # Get the index of the max log-probability\n",
        "    final_pred = output.max(1, keepdim=True)[1]\n",
        "    if final_pred.item() == target.item():\n",
        "      correct += 1\n",
        "      # Special case for saving 0 epsilon examples\n",
        "      if (epsilon == 0) and (len(adv_examples) < 5):\n",
        "        adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
        "        adv_examples.append( (target.item(), final_pred.item(), adv_ex) )\n",
        "    else:\n",
        "      # Save some adv examples for visualization later\n",
        "      if len(adv_examples) < 5:\n",
        "        adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
        "        adv_examples.append( (target.item(), final_pred.item(), adv_ex) )\n",
        "\n",
        "  # Calculate final accuracy for this epsilon\n",
        "  final_acc = correct/float(len(test_loader))\n",
        "  print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n",
        "\n",
        "  # Return the accuracy and adversarial examples\n",
        "  return final_acc, adv_examples\n",
        "\n",
        "# Display adversarial examples\n",
        "def display_examples(epsilons, examples):\n",
        "  cnt = 0\n",
        "  plt.figure(figsize=(8,10))\n",
        "  for i in range(len(epsilons)):\n",
        "    for j in range(len(examples[i])):\n",
        "      cnt += 1\n",
        "      plt.subplot(len(epsilons),len(examples[0]),cnt)\n",
        "      plt.xticks([], [])\n",
        "      plt.yticks([], [])\n",
        "      if j == 0:\n",
        "        plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n",
        "      orig,adv,ex = examples[i][j]\n",
        "      plt.title(\"{} -> {}\".format(orig, adv))\n",
        "      plt.imshow(ex, cmap=\"gray\")\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ubzvEsGEdW_"
      },
      "source": [
        "### Fast gradient sign method (FGSM) attack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv6APafNDpy-"
      },
      "source": [
        "Run the cell below to\n",
        "\n",
        "*   define `fgsm_attack()` as an implementation of FGSM\n",
        "*   run the FGSM attack against all images in the test set for several values of `epsilon`\n",
        "*   collect accuracy statistics and display sample adversarial examples\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J31S40UZPJ9h"
      },
      "outputs": [],
      "source": [
        "# FGSM attack code\n",
        "def fgsm_attack(image, target, epsilon):\n",
        "  # Forward pass the data through the model\n",
        "  output = model(image)\n",
        "  # Calculate the loss\n",
        "  loss = F.nll_loss(output, target)\n",
        "  # Zero all existing gradients\n",
        "  model.zero_grad()\n",
        "  # Calculate gradients of model in backward pass\n",
        "  loss.backward()\n",
        "  # Collect the element-wise sign of the data gradient\n",
        "  sign_data_grad = image.grad.data.sign()\n",
        "  # Create the perturbed image by adjusting each pixel of the input image\n",
        "  perturbed_image = image + epsilon*sign_data_grad\n",
        "  # Clip to maintain [0,1] range\n",
        "  perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "  # Return the perturbed image\n",
        "  return perturbed_image\n",
        "\n",
        "# Epsilon values for FGSM attack\n",
        "# Pixel value range is [0,1] so epsilon < 1\n",
        "epsilons = [0, .05, .1, .15, .2, .25, .3]\n",
        "\n",
        "accuracies_fgsm = []\n",
        "examples_fgsm = []\n",
        "\n",
        "# Run test for each epsilon\n",
        "for eps in epsilons:\n",
        "  acc, ex = test(fgsm_attack, model, device, test_loader, eps)\n",
        "  accuracies_fgsm.append(acc)\n",
        "  examples_fgsm.append(ex)\n",
        "\n",
        "# Plot several examples of adversarial samples at each epsilon\n",
        "display_examples(epsilons, examples_fgsm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtYcka2FFE92"
      },
      "source": [
        "### Iterative method attack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uV_gx-eZFJSH"
      },
      "source": [
        "**3.1** (30 pts) Complete the function `iterative_attack()` to implement the iterative method attack described in the lecture titled *Evasion Attacks on Neural Network Classifiers.* Use the provided values of `num_iterations = 3` and `alpha = epsilon/2`.\n",
        "\n",
        "Note that you should **not** modify the argument `image` because it is a special object that maintains a field called `grad` necessary for backpropagation. Instead we have initialized a tensor called `delta` that you can use to perturb the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZVxHecbJwj_"
      },
      "outputs": [],
      "source": [
        "# Iterative method attack code\n",
        "def iterative_attack(image, target, epsilon):\n",
        "\n",
        "  num_iterations = 3\n",
        "  alpha = epsilon/2\n",
        "  delta = torch.zeros(image.shape).to(device)\n",
        "\n",
        "  # START EDITING HERE - DON'T REMOVE THIS COMMENT\n",
        "\n",
        "  # END EDITING HERE - DON'T REMOVE THIS COMMENT\n",
        "\n",
        "  # Return the perturbed image\n",
        "  perturbed_image = torch.clamp(image+delta, 0, 1)\n",
        "  return perturbed_image\n",
        "\n",
        "accuracies_iterative = []\n",
        "examples_iterative = []\n",
        "\n",
        "# Run test for each epsilon\n",
        "for eps in epsilons:\n",
        "  acc, ex = test(iterative_attack, model, device, test_loader, eps)\n",
        "  accuracies_iterative.append(acc)\n",
        "  examples_iterative.append(ex)\n",
        "\n",
        "# Plot several examples of adversarial samples at each epsilon\n",
        "display_examples(epsilons, examples_iterative)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHN_NEkmJ79_"
      },
      "source": [
        "Run the cell below to compare the accuracies under FGSM and iterative method attacks. You should see that the iterative method degrades accuracy more significantly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WT3HNOdPR-G3"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "plt.plot(epsilons, accuracies_fgsm, 'b*-', label='FGSM')\n",
        "plt.plot(epsilons, accuracies_iterative, 'ro-', label='iterative method')\n",
        "plt.yticks(np.arange(0, 1.1, step=0.1))\n",
        "plt.xticks(np.arange(0, .35, step=0.05))\n",
        "plt.legend(loc='lower left')\n",
        "plt.xlabel('epsilon')\n",
        "plt.ylabel('accuracy')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qgMATknLNQI"
      },
      "source": [
        "### Targeted iterative method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8G1kAGr3LGQy"
      },
      "source": [
        "**3.2** (30 pts) Complete the function `targeted_iterative_attack()` to implement the targeted iterative method attack described in the lecture titled *Evasion Attacks on Neural Network Classifiers.* Your attack should attempt to perturb `image` so that it gets classified as `target_digit = 8`. Continue to use the provided values of `num_iterations = 3` and `alpha = epsilon/2`.\n",
        "\n",
        "If your implementation is correct you will see convincing evidence among the adversarial images displayed by this cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1irz7KFN955"
      },
      "outputs": [],
      "source": [
        "# Targeted iterative method attack code\n",
        "def targeted_iterative_attack(image, target, epsilon):\n",
        "\n",
        "  target_digit = 8\n",
        "\n",
        "  num_iterations = 3\n",
        "  alpha = epsilon/2\n",
        "  delta = torch.zeros(image.shape).to(device)\n",
        "\n",
        "  # START EDITING HERE - DON'T REMOVE THIS COMMENT\n",
        "\n",
        "  # END EDITING HERE - DON'T REMOVE THIS COMMENT\n",
        "\n",
        "  # Return the perturbed image\n",
        "  perturbed_image = torch.clamp(image+delta, 0, 1)\n",
        "  return perturbed_image\n",
        "\n",
        "accuracies_targeted = []\n",
        "examples_targeted = []\n",
        "\n",
        "# Run test for each epsilon\n",
        "for eps in epsilons:\n",
        "  acc, ex = test(targeted_iterative_attack, model, device, test_loader, eps)\n",
        "  accuracies_targeted.append(acc)\n",
        "  examples_targeted.append(ex)\n",
        "\n",
        "# Plot several examples of adversarial samples at each epsilon\n",
        "display_examples(epsilons, examples_targeted)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
