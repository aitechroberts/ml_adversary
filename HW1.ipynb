{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YYdtMW7eZjk"
      },
      "source": [
        "#14757 Homework 1  (150 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QRhbSQO7aHZ"
      },
      "source": [
        "## **Due:** Wednesday September 18 at 3pm ET / 12 noon PT\n",
        "\n",
        "## Submission Instructions\n",
        "\n",
        "*   Download your completed notebook by clicking File->Download .ipynb and submit it on Gradescope\n",
        "*   Check your submission on Gradescope to make sure that all your code, code output and written responses appear correctly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tdp9iNT17pPr"
      },
      "source": [
        "## Problem 1: Gradescope Autograder Placeholder (0 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JEUcMu_7qJH"
      },
      "source": [
        "Gradescope requires that problem 1 be autograded for code submissions, but there are no autograded problems. Continue to problem 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgPiRgPROYhy"
      },
      "source": [
        "## Problem 2: The Wrongful Conviction of Sally Clark (20 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nT9ImalpOgQ5"
      },
      "source": [
        "Sally Clark was a British lawyer who was wrongly sentenced to life in prison in 1999 for the deaths of her two infant children. Her elder son Christopher died at age 11 weeks in December 1996 and her younger son Harry at 8 weeks in January 1998. At her trial, the defence argued that the deaths were due to sudden infant death syndrome (SIDS). Clark was convicted on the basis of testimony by pediatrician Sir Roy Meadow, who made the following argument:\n",
        "\n",
        "*   Hospital records show that the ratio of SIDS deaths to live births in affluent non-smoking families is about $\\frac{1}{8500}$. (A live birth is a birth in which a child is born alive; not a still birth.)\n",
        "*   The chance of two SIDS deaths occurring in the same family is about $\\frac{1}{8500^2} \\approx \\frac{1}{73000000}$.\n",
        "*   It is therefore extremely unlikely that Clark is innocent.\n",
        "\n",
        "As a result of this prosecution, Clark spent more than 3 years in prison and was finally exonerated in 2003 after it was determined that Meadow’s expert testimony was flawed. Two other women against whom Meadow provided expert testimony had their convictions overturned as well.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a--FKi6P7_1"
      },
      "source": [
        "**2.1** (10 pts) Identify a flaw in Meadow’s $\\frac{1}{73000000}$ figure.\n",
        "\n",
        "WRITE YOUR ANSWER HERE:\n",
        "The problem with Meadow's figure is that he assumes conditional independence meaning that the 2 infant deaths are uncorrelated such that the probability of 2x SIDS deaths in the same family is 1/8500. However, Meadows being a pediatrician should recognize that 2 children being afflicted with the same disease coming from the same is not conditionally independent, and therefore his assumption would fail thus rendering his figure completely incorrect."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATt9DojYQaAH"
      },
      "source": [
        "**2.2** (10 pts) Even if we accept Meadow’s $\\frac{1}{73000000}$ calculation as valid, what is wrong with a juror interpreting it as the probability of Clark’s innocence?\n",
        "\n",
        "WRITE YOUR ANSWER HERE:\n",
        "Even if we accept Meadow's Number as valid, the juror should not be concerned with Meadow's Number as his calculation gives the probability of 2x SIDS deaths given Clark's innocence P(2x SIDS Deaths | Clark's Innocence). First and foremost, the juror should be concerned with the probability that Clark is innocent given the two natural infant deaths regardless of cause, and that equation would be {P(2x Infant Deaths | Innocence) * P(Innocence)/P(2x Natural Infant Deaths)}. It stands to reason that $P(2x SIDS Deaths | Clark's Innocence) != P(Innocence | 2x Natural Infant Deaths)$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPofMMlMAigz"
      },
      "source": [
        "## Problem 3: Attacking a Multinomial Naive Bayes Spam Filter (80 pts)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqY3xKbxkSV_"
      },
      "source": [
        "In this problem you will execute several attacks on a naive Bayes spam filter for text messages (SMS). Run the cell below to set up the spam filter. The code performs the following steps:\n",
        "\n",
        "*   Reading and displaying the data\n",
        "*   Splitting the data into training and testing sets\n",
        "*   Converting each text message into a vector of word counts, so that the training messages are represented as a single matrix, and so are the test messages\n",
        "*   Training the spam filter using the training set and evaluating it with respect to the testing set\n",
        "\n",
        "Helpful documentation:\n",
        "\n",
        "*   https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
        "*   https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n",
        "\n",
        "This implementation is adapted from source code here: https://github.com/rahulvasaikar/SMS-spam-Detection\n",
        "\n",
        "The original data is documented here: https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0uBdoRUln_w"
      },
      "outputs": [],
      "source": [
        "# READING AND DISPLAYING DATA\n",
        "\n",
        "# Reading tab separated text file into a Pandas dataframe\n",
        "import pandas as pd\n",
        "url = 'http://www.andrew.cmu.edu/user/dvaroday/14757/data/hw1/SMSSpamCollection'\n",
        "df = pd.read_table(url, sep='\\t', names=['label', 'message'])\n",
        "\n",
        "# Mapping ham/spam labels to 0/1\n",
        "df['binary_label'] = df.label.map({'ham':0,'spam':1})\n",
        "\n",
        "# Display dataframe\n",
        "print('DATASET')\n",
        "display(df)\n",
        "\n",
        "# SPLITTING INTO TRAINING AND TESTING SETS\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['message'],\n",
        "                                        df['binary_label'], random_state=1)\n",
        "\n",
        "total_rows = df.shape[0]\n",
        "training_rows = X_train.shape[0]\n",
        "test_rows = X_test.shape[0]\n",
        "\n",
        "print('\\nDATA SPLIT STATISTICS')\n",
        "print('Number of rows in the total set:    {}'.format(total_rows))\n",
        "print('Number of rows in the training set: {}'.format(training_rows))\n",
        "print('Number of rows in the test set:     {}'.format(test_rows))\n",
        "\n",
        "# CONVERTING EACH TEXT MESSAGE INTO A VECTOR OF WORD COUNTS\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# Instantiate the CountVectorizer\n",
        "count_vector = CountVectorizer()\n",
        "\n",
        "# Fit the training data\n",
        "# Returns matrix of feature counts in training text messages\n",
        "# Features are obtained from the training set itself\n",
        "training_data = count_vector.fit_transform(X_train)\n",
        "\n",
        "# Transform testing data\n",
        "# Returns matrix of feature counts in test text messages\n",
        "# Note that the features are the ones obtained from the training set\n",
        "testing_data = count_vector.transform(X_test)\n",
        "\n",
        "# TRAINING AND EVALUATING MODEL\n",
        "\n",
        "# Train\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "# MultinomialNB with Laplacian smoothing (alpha=1.0)\n",
        "spam_filter = MultinomialNB(alpha=1.0)\n",
        "spam_filter.fit(training_data, y_train)\n",
        "\n",
        "# Evaluate\n",
        "predictions = spam_filter.predict(testing_data)\n",
        "from sklearn.metrics import accuracy_score, recall_score\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "recall = recall_score(y_test, predictions)\n",
        "\n",
        "print('\\nPERFORMANCE')\n",
        "print('Accuracy:', \"{:.3f}\".format(accuracy))\n",
        "print('Recall:  ', \"{:.3f}\".format(recall))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHA_NGh6l_lA"
      },
      "source": [
        "### Understanding baseline performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btlqwb6fT6qv"
      },
      "source": [
        "**3.1** (10 pts) In the cell above *accuracy* is the fraction of messages that are correctly classified by the spam filter. *Recall* is the fraction of true spam messages correctly classified as spam. But the message recipient cares about true ham messages that are classified as spam because these messages are filtered out by the spam filter. Neither accuracy nor recall address this issue directly. Instead, the metric *specificity* represents the fraction of true ham messages that the recipient will actually receive. Fix the code between the comments in the cell below to calculate specificity for the test set.\n",
        "\n",
        "https://en.wikipedia.org/wiki/Precision_and_recall\n",
        "\n",
        "https://en.wikipedia.org/wiki/Sensitivity_and_specificity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFsMZ2d0vqjx"
      },
      "outputs": [],
      "source": [
        "def specificity_score(y_test, predictions):\n",
        "  test_messages = len(y_test.values)\n",
        "  true_spams = sum(y_test.values)\n",
        "  positives = sum(predictions)\n",
        "  true_positives = sum(y_test.values * predictions)\n",
        "\n",
        "  # START EDITING HERE - DON'T REMOVE THIS COMMENT\n",
        "  return 0\n",
        "  # END EDITING HERE - DON'T REMOVE THIS COMMENT\n",
        "\n",
        "specificity = specificity_score(y_test, predictions)\n",
        "print('Specificity:', \"{:.3f}\".format(specificity))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzaAb5ePmHbr"
      },
      "source": [
        "### Evasion attack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOOScxPGNZIX"
      },
      "source": [
        "**3.2** (10 pts) In this part you act as a spammer who wants to evades the spam filter. Edit `evasion_message` in the cell below so that its probability of being labeled spam becomes less than 1%. For full credit, `evasion_message` must convey the same meaning as `original_message`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJv2uPnZ8iq7"
      },
      "outputs": [],
      "source": [
        "original_message = 'Txt back to get your $1000 prize now'\n",
        "\n",
        "# EDIT THE MESSAGE BELOW - DON'T REMOVE THIS COMMENT\n",
        "evasion_message = 'Text me back now to receive the contest prize money that you are owed in the amount of one thousand dollars'\n",
        "\n",
        "# Probabilistic predictions of original_message and evasion_message\n",
        "df_evasion = pd.DataFrame([original_message, evasion_message],\n",
        "                          columns=['message'])\n",
        "message_data = count_vector.transform(df_evasion['message'])\n",
        "prediction_probabilities = spam_filter.predict_proba(message_data)\n",
        "\n",
        "print('Probability that original message is spam: ',\n",
        "      \"{:.6f}\".format(prediction_probabilities[0,1]))\n",
        "print('Probability that evasion message is spam:  ',\n",
        "      \"{:.6f}\".format(prediction_probabilities[1,1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHMHe2rZ33Hi"
      },
      "source": [
        "**3.3** (10 pts) Describe the process you used to create your `evasion_message` in 1-2 sentences. Was this an open box (whitebox) or closed box (blackbox) attack? If open box, specify what information about `spam_filter` you used.\n",
        "\n",
        "WRITE YOUR ANSWER HERE:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybxd3mdKmPIj"
      },
      "source": [
        "### Poisoning attack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CUlek4uT_yP"
      },
      "source": [
        "**3.4** (10 pts) In this part you play the role of an adversary working against a ride share company. The company wants to deliver `target_message` to its customers. You gain access to the training set and have the opportunity to poison the training data with one poison message/label pair, but your example may be rejected by the spam filter administrator. Edit `poison_message` and/or `poison_label` so that they are accepted by the administrator and make the probability of `target_message` being labeled spam greater than 50%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlGoee3Uw-e_"
      },
      "outputs": [],
      "source": [
        "target_message = 'Your ride share has arrived'\n",
        "df_target = pd.DataFrame([target_message], columns=['message'])\n",
        "target_data = count_vector.transform(df_target['message'])\n",
        "target_probabilities = spam_filter.predict_proba(target_data)\n",
        "print('Probability that target message is spam before poisoning:',\n",
        "      \"{:.6f}\".format(target_probabilities[0,1]))\n",
        "\n",
        "# START EDITING HERE - DON'T REMOVE THIS COMMENT\n",
        "poison_message = ''\n",
        "poison_label = 0\n",
        "# END EDITING HERE - DON'T REMOVE THIS COMMENT\n",
        "\n",
        "# Administrator runs poison message through original spam filter\n",
        "# to validate its label\n",
        "df_poison = pd.DataFrame([[poison_message, poison_label]],\n",
        "                         columns=['message', 'binary_label'])\n",
        "poison_data = count_vector.transform(df_poison['message'])\n",
        "poison_validation = spam_filter.predict(poison_data)\n",
        "\n",
        "if poison_label != poison_validation[0]:\n",
        "\n",
        "  print('Administrator rejects your poison message/label')\n",
        "\n",
        "else:\n",
        "\n",
        "  print('Administrator accepts your poison message/label')\n",
        "\n",
        "  # Initialize retraining data with original training data and append poison\n",
        "  df_retrain = pd.DataFrame(X_train, columns=['message'])\n",
        "  df_retrain['binary_label'] = y_train.values\n",
        "  df_retrain = pd.concat([df_retrain, df_poison], ignore_index=True)\n",
        "\n",
        "  # Retrain\n",
        "  recount_vector = CountVectorizer()\n",
        "  retraining_data = recount_vector.fit_transform(df_retrain['message'])\n",
        "  retrained_filter = MultinomialNB(alpha=1.0)\n",
        "  retrained_filter.fit(retraining_data, df_retrain['binary_label'])\n",
        "\n",
        "  # Evaluate target message with retrained_filter\n",
        "  recount_target_data = recount_vector.transform(df_target['message'])\n",
        "  poisoned_probabilities = retrained_filter.predict_proba(recount_target_data)\n",
        "\n",
        "  print('Probability that target message is spam after poisoning: ',\n",
        "        \"{:.6f}\".format(poisoned_probabilities[0,1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0H6C9ZmbHIm"
      },
      "source": [
        "**3.5** (10 pts) Describe an additional way for the administrator to decide whether to reject the poison message/label pair in order to defend against this type of attack. Use 1-4 sentences in your answer.\n",
        "\n",
        "WRITE YOUR ANSWER HERE:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbwFzD5JmSgL"
      },
      "source": [
        "### Reverse engineering attack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YG0pKLgKC23l"
      },
      "source": [
        "**3.6** (20 pts) In this part you will perform a reverse engineering attack against the spam filter administrator. Your goal is to reconstruct the `spam_filter` model without using any of the original training messages or labels. In the starter code below the attacker sends a set of `probe_messages` to the `spam_filter`. The attacker can detect whether each message has been classified as spam or ham by inspecting its read receipt. The attacker uses these classifications as labels to train `reconstructed_filter`.\n",
        "\n",
        "Edit `probe_messages` so that `reconstructed_filter` achieves at least 97% accuracy and 88% recall on the test set. You can use at most `max_probes = 5000` probe messages. You may **not** use the training or test sets to help construct `probe_messages`, **except** for the list of words provided to you in the list `vocab`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghUlVDXg176d"
      },
      "outputs": [],
      "source": [
        "max_probes = 5000\n",
        "vocab = count_vector.get_feature_names_out()\n",
        "\n",
        "# START EDITING HERE - DON'T REMOVE THIS COMMENT\n",
        "probe_messages = ['probe ' + str(i) for i in range(max_probes)]\n",
        "# END EDITING HERE - DON'T REMOVE THIS COMMENT\n",
        "\n",
        "print('Number of probe messages:', len(probe_messages))\n",
        "\n",
        "# Run probe_messages through spam_filter to obtain probe_labels\n",
        "df_probes = pd.DataFrame(probe_messages, columns=['message'])\n",
        "probe_data = count_vector.transform(df_probes['message'])\n",
        "probe_labels = spam_filter.predict(probe_data)\n",
        "\n",
        "# Train reconstructed_filter using probe_messages and probe_labels\n",
        "reconstructed_filter = MultinomialNB(alpha=1.0)\n",
        "reconstructed_filter.fit(probe_data, probe_labels)\n",
        "reconstructed_predictions = reconstructed_filter.predict(testing_data)\n",
        "\n",
        "# Evaluate\n",
        "accuracy = accuracy_score(y_test, reconstructed_predictions)\n",
        "recall = recall_score(y_test, reconstructed_predictions)\n",
        "\n",
        "print('Accuracy:', \"{:.3f}\".format(accuracy))\n",
        "print('Recall:  ', \"{:.3f}\".format(recall))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esBEzGGIX8o2"
      },
      "source": [
        "**3.7** (10 pts) Describe one way that the administrator can defend against this type of attack. Use 1-4 sentences in your answer.\n",
        "\n",
        "WRITE YOUR ANSWER HERE:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGHknXEild0S"
      },
      "source": [
        "## Problem 4: Implementing a Multinomial Naive Bayes Classifier (50 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylq5ANqCJJ9Q"
      },
      "source": [
        "In this problem you will implement a Multinomial Naive Bayes classifier from scratch that performs identically to the one from the `sklearn.naive_bayes` library you used above. First run the cell below to load the preprocess the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lzw9fLp0I3O0"
      },
      "outputs": [],
      "source": [
        "# Reading tab separated text file into a Pandas dataframe\n",
        "import pandas as pd\n",
        "url = 'http://www.andrew.cmu.edu/user/dvaroday/14757/data/hw1/SMSSpamCollection'\n",
        "df = pd.read_table(url, sep='\\t', names=['label', 'message'])\n",
        "\n",
        "# Mapping ham/spam labels to 0/1\n",
        "df['binary_label'] = df.label.map({'ham':0,'spam':1})\n",
        "\n",
        "# Splitting into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['message'],\n",
        "                                        df['binary_label'], random_state=1)\n",
        "\n",
        "# Converting each text message into a vector of word counts\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vector = CountVectorizer()\n",
        "training_data = count_vector.fit_transform(X_train)\n",
        "testing_data = count_vector.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lnMSilVmayD"
      },
      "source": [
        "In the cell below complete the class `MultinomialNB` by implementing the `fit()` and `predict()` methods. The constructor `__init__()` is written for you but you can modify it according to your needs.\n",
        "\n",
        "For full credit your implementation should not use any loops. Instead you should operate directly on vectors and matrices, not iterate through them. In particular your `fit()` method should calculate log-probability ratios with `np.log()` so that your `predict()` method can use `np.matmul()` for matrix multiplication. For your convenience the starter code already converts the method inputs into `numpy` arrays. Here's a guide to vectorization and broadcasting with `numpy`: https://realpython.com/numpy-array-programming\n",
        "\n",
        "Make the following assumptions:\n",
        "\n",
        "*   The classification task is binary. Specifically `train_labels` is a vector of values 0 and 1 only.\n",
        "*   The feature values in `train_features` and `test_features` are nonnegative integers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMVLzHIdsazP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# START EDITING HERE - DON'T REMOVE THIS COMMENT\n",
        "\n",
        "class MultinomialNB:\n",
        "\n",
        "  def __init__(self, alpha):\n",
        "    self.alpha = alpha # Equal to 1.0 for Laplace smoothing\n",
        "    self.label_log_prob_ratio = None\n",
        "    self.feature_log_prob_ratios = None\n",
        "\n",
        "  def fit(self, train_features, train_labels):\n",
        "    # Converting inputs to numpy arrays\n",
        "    train_features = np.array(train_features.todense())\n",
        "    train_labels = np.array(train_labels.values)\n",
        "\n",
        "  def predict(self, test_features):\n",
        "    # Converting input to numpy arrays\n",
        "    test_features = np.array(test_features.todense())\n",
        "    # Initializing return value\n",
        "    preds = np.zeros(test_features.shape[0], dtype=np.uint8)\n",
        "    return preds\n",
        "\n",
        "# END EDITING HERE - DON'T REMOVE THIS COMMENT\n",
        "\n",
        "\n",
        "\n",
        "### DO NOT EDIT THE CODE BELOW THIS LINE\n",
        "\n",
        "# Train\n",
        "# MultinomialNB with Laplacian smoothing (alpha=1.0)\n",
        "spam_filter = MultinomialNB(alpha=1.0)\n",
        "spam_filter.fit(training_data, y_train)\n",
        "\n",
        "# Evaluate\n",
        "predictions = spam_filter.predict(testing_data)\n",
        "from sklearn.metrics import accuracy_score, recall_score\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "recall = recall_score(y_test, predictions)\n",
        "print('\\nPERFORMANCE')\n",
        "print('Accuracy:', \"{:.3f}\".format(accuracy))\n",
        "print('Recall:  ', \"{:.3f}\".format(recall))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
